[0m15:56:59.195579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49748cc370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4972f6dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4972f6fbb0>]}


============================== 15:56:59.201543 | 5ea8f678-b7c8-433e-bc7e-82c58299fc22 ==============================
[0m15:56:59.201543 [info ] [MainThread]: Running with dbt=1.7.11
[0m15:56:59.202633 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/data_jobs/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/data_jobs/data_pipeline/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:57:00.608026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4974f3ca00>]}
[0m15:57:00.735524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4953fd2bb0>]}
[0m15:57:00.736891 [info ] [MainThread]: Registered adapter: bigquery=1.7.7
[0m15:57:00.748727 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m15:57:00.749772 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:57:00.750509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4953f53f40>]}
[0m15:57:02.430835 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.data_pipeline.core
- models.data_pipeline.staging
[0m15:57:02.439021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951b890d0>]}
[0m15:57:02.459288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4953f7c670>]}
[0m15:57:02.460218 [info ] [MainThread]: Found 2 models, 4 tests, 0 sources, 0 exposures, 0 metrics, 454 macros, 0 groups, 0 semantic models
[0m15:57:02.460906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4953efb3d0>]}
[0m15:57:02.463125 [info ] [MainThread]: 
[0m15:57:02.464433 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m15:57:02.466518 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_de-data-jobs'
[0m15:57:02.467394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:02.679968 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_de-data-jobs, now list_de-data-jobs_dbt_db)
[0m15:57:02.680911 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:57:02.858768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951c04550>]}
[0m15:57:02.860453 [info ] [MainThread]: Concurrency: 10 threads (target='dev')
[0m15:57:02.861303 [info ] [MainThread]: 
[0m15:57:02.868702 [debug] [Thread-1  ]: Began running node model.data_pipeline.my_first_dbt_model
[0m15:57:02.869814 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_db.my_first_dbt_model ......................... [RUN]
[0m15:57:02.871310 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_de-data-jobs_dbt_db, now model.data_pipeline.my_first_dbt_model)
[0m15:57:02.872089 [debug] [Thread-1  ]: Began compiling node model.data_pipeline.my_first_dbt_model
[0m15:57:02.884164 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_pipeline.my_first_dbt_model"
[0m15:57:02.886102 [debug] [Thread-1  ]: Timing info for model.data_pipeline.my_first_dbt_model (compile): 15:57:02.872662 => 15:57:02.885643
[0m15:57:02.886815 [debug] [Thread-1  ]: Began executing node model.data_pipeline.my_first_dbt_model
[0m15:57:02.942485 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_pipeline.my_first_dbt_model"
[0m15:57:02.943810 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:57:02.949646 [debug] [Thread-1  ]: On model.data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "model.data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `de-data-jobs`.`dbt_db`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m15:57:03.443260 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:175b64ba-f937-4aa3-94b8-9499fc71ca4a&page=queryresults
[0m15:57:05.410852 [debug] [Thread-1  ]: Timing info for model.data_pipeline.my_first_dbt_model (execute): 15:57:02.887220 => 15:57:05.410458
[0m15:57:05.412473 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951ac2ca0>]}
[0m15:57:05.413720 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_db.my_first_dbt_model .................... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.54s]
[0m15:57:05.414884 [debug] [Thread-1  ]: Finished running node model.data_pipeline.my_first_dbt_model
[0m15:57:05.416611 [debug] [Thread-3  ]: Began running node model.data_pipeline.my_second_dbt_model
[0m15:57:05.417636 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_db.my_second_dbt_model ......................... [RUN]
[0m15:57:05.419116 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.data_pipeline.my_second_dbt_model'
[0m15:57:05.419890 [debug] [Thread-3  ]: Began compiling node model.data_pipeline.my_second_dbt_model
[0m15:57:05.430940 [debug] [Thread-3  ]: Writing injected SQL for node "model.data_pipeline.my_second_dbt_model"
[0m15:57:05.432458 [debug] [Thread-3  ]: Timing info for model.data_pipeline.my_second_dbt_model (compile): 15:57:05.420387 => 15:57:05.432029
[0m15:57:05.433216 [debug] [Thread-3  ]: Began executing node model.data_pipeline.my_second_dbt_model
[0m15:57:05.461466 [debug] [Thread-3  ]: Writing runtime sql for node "model.data_pipeline.my_second_dbt_model"
[0m15:57:05.462588 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m15:57:05.468547 [debug] [Thread-3  ]: On model.data_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "model.data_pipeline.my_second_dbt_model"} */


  create or replace view `de-data-jobs`.`dbt_db`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `de-data-jobs`.`dbt_db`.`my_first_dbt_model`
where id = 1;


[0m15:57:05.903926 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:57e2d2ed-950c-4f74-be24-b66fb8993b4e&page=queryresults
[0m15:57:06.150328 [debug] [Thread-3  ]: Timing info for model.data_pipeline.my_second_dbt_model (execute): 15:57:05.433705 => 15:57:06.149935
[0m15:57:06.151777 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea8f678-b7c8-433e-bc7e-82c58299fc22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951b0d160>]}
[0m15:57:06.152842 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_db.my_second_dbt_model .................... [[32mCREATE VIEW (0 processed)[0m in 0.73s]
[0m15:57:06.153840 [debug] [Thread-3  ]: Finished running node model.data_pipeline.my_second_dbt_model
[0m15:57:06.157392 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:57:06.157976 [debug] [MainThread]: Connection 'model.data_pipeline.my_first_dbt_model' was properly closed.
[0m15:57:06.158524 [debug] [MainThread]: Connection 'model.data_pipeline.my_second_dbt_model' was properly closed.
[0m15:57:06.159252 [info ] [MainThread]: 
[0m15:57:06.159882 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m15:57:06.161198 [debug] [MainThread]: Command end result
[0m15:57:06.174391 [info ] [MainThread]: 
[0m15:57:06.175232 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:57:06.175861 [info ] [MainThread]: 
[0m15:57:06.176470 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:57:06.177302 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.0500336, "process_user_time": 6.210655, "process_kernel_time": 0.283222, "process_mem_max_rss": "240084", "process_in_blocks": "96", "process_out_blocks": "2800"}
[0m15:57:06.178183 [debug] [MainThread]: Command `dbt run` succeeded at 15:57:06.177960 after 7.05 seconds
[0m15:57:06.178918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49748cc370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4953cce970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4953fd2bb0>]}
[0m15:57:06.179573 [debug] [MainThread]: Flushing usage events
[0m16:00:17.688761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd0b051580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd096eb7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd096eb550>]}


============================== 16:00:17.694744 | 8de25caa-b973-46ee-84c0-2221a67f3ecc ==============================
[0m16:00:17.694744 [info ] [MainThread]: Running with dbt=1.7.11
[0m16:00:17.695724 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/home/data_jobs/.dbt', 'log_path': '/home/data_jobs/data_pipeline/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m16:00:19.132775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd09754880>]}
[0m16:00:19.266099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccea5d1c40>]}
[0m16:00:19.267478 [info ] [MainThread]: Registered adapter: bigquery=1.7.7
[0m16:00:19.280851 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m16:00:19.296304 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:00:19.297434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccea642dc0>]}
[0m16:00:21.033287 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.data_pipeline.staging
- models.data_pipeline.core
[0m16:00:21.042808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce83070d0>]}
[0m16:00:21.066393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce83f4cd0>]}
[0m16:00:21.067584 [info ] [MainThread]: Found 2 models, 4 tests, 0 sources, 0 exposures, 0 metrics, 454 macros, 0 groups, 0 semantic models
[0m16:00:21.068545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce8462820>]}
[0m16:00:21.071013 [info ] [MainThread]: 
[0m16:00:21.072800 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m16:00:21.075665 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_de-data-jobs'
[0m16:00:21.076975 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:21.338059 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_de-data-jobs, now list_de-data-jobs_dbt_dw)
[0m16:00:21.339065 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:00:21.514842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce83f4250>]}
[0m16:00:21.516674 [info ] [MainThread]: Concurrency: 10 threads (target='dev')
[0m16:00:21.517500 [info ] [MainThread]: 
[0m16:00:21.523540 [debug] [Thread-1  ]: Began running node model.data_pipeline.my_first_dbt_model
[0m16:00:21.524960 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_dw.my_first_dbt_model ......................... [RUN]
[0m16:00:21.526826 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_de-data-jobs_dbt_dw, now model.data_pipeline.my_first_dbt_model)
[0m16:00:21.527720 [debug] [Thread-1  ]: Began compiling node model.data_pipeline.my_first_dbt_model
[0m16:00:21.540515 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_pipeline.my_first_dbt_model"
[0m16:00:21.542416 [debug] [Thread-1  ]: Timing info for model.data_pipeline.my_first_dbt_model (compile): 16:00:21.528304 => 16:00:21.541926
[0m16:00:21.543356 [debug] [Thread-1  ]: Began executing node model.data_pipeline.my_first_dbt_model
[0m16:00:21.600660 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_pipeline.my_first_dbt_model"
[0m16:00:21.601945 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:00:21.607886 [debug] [Thread-1  ]: On model.data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "model.data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `de-data-jobs`.`dbt_dw`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m16:00:22.085302 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:1397bb36-67b6-4028-ae2a-0ee4f038e140&page=queryresults
[0m16:00:24.341744 [debug] [Thread-1  ]: Timing info for model.data_pipeline.my_first_dbt_model (execute): 16:00:21.543933 => 16:00:24.341357
[0m16:00:24.343340 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce823dbb0>]}
[0m16:00:24.344530 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_dw.my_first_dbt_model .................... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.82s]
[0m16:00:24.345628 [debug] [Thread-1  ]: Finished running node model.data_pipeline.my_first_dbt_model
[0m16:00:24.347305 [debug] [Thread-3  ]: Began running node model.data_pipeline.my_second_dbt_model
[0m16:00:24.348172 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_dw.my_second_dbt_model ......................... [RUN]
[0m16:00:24.349569 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.data_pipeline.my_second_dbt_model'
[0m16:00:24.350241 [debug] [Thread-3  ]: Began compiling node model.data_pipeline.my_second_dbt_model
[0m16:00:24.355737 [debug] [Thread-3  ]: Writing injected SQL for node "model.data_pipeline.my_second_dbt_model"
[0m16:00:24.356950 [debug] [Thread-3  ]: Timing info for model.data_pipeline.my_second_dbt_model (compile): 16:00:24.350901 => 16:00:24.356540
[0m16:00:24.357613 [debug] [Thread-3  ]: Began executing node model.data_pipeline.my_second_dbt_model
[0m16:00:24.387382 [debug] [Thread-3  ]: Writing runtime sql for node "model.data_pipeline.my_second_dbt_model"
[0m16:00:24.388558 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:00:24.394570 [debug] [Thread-3  ]: On model.data_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "model.data_pipeline.my_second_dbt_model"} */


  create or replace view `de-data-jobs`.`dbt_dw`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `de-data-jobs`.`dbt_dw`.`my_first_dbt_model`
where id = 1;


[0m16:00:24.806037 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:7c570617-1e48-4545-98bc-0a0832111229&page=queryresults
[0m16:00:25.249312 [debug] [Thread-3  ]: Timing info for model.data_pipeline.my_second_dbt_model (execute): 16:00:24.358027 => 16:00:25.248924
[0m16:00:25.250953 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8de25caa-b973-46ee-84c0-2221a67f3ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce8281730>]}
[0m16:00:25.252209 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_dw.my_second_dbt_model .................... [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m16:00:25.253348 [debug] [Thread-3  ]: Finished running node model.data_pipeline.my_second_dbt_model
[0m16:00:25.257154 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:25.257903 [debug] [MainThread]: Connection 'model.data_pipeline.my_first_dbt_model' was properly closed.
[0m16:00:25.258600 [debug] [MainThread]: Connection 'model.data_pipeline.my_second_dbt_model' was properly closed.
[0m16:00:25.259370 [info ] [MainThread]: 
[0m16:00:25.260368 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.19 seconds (4.19s).
[0m16:00:25.262286 [debug] [MainThread]: Command end result
[0m16:00:25.275859 [info ] [MainThread]: 
[0m16:00:25.276692 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:00:25.277291 [info ] [MainThread]: 
[0m16:00:25.277898 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:00:25.278820 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.6584344, "process_user_time": 6.309452, "process_kernel_time": 0.307234, "process_mem_max_rss": "240744", "process_out_blocks": "2816", "process_in_blocks": "0"}
[0m16:00:25.279781 [debug] [MainThread]: Command `dbt run` succeeded at 16:00:25.279557 after 7.66 seconds
[0m16:00:25.280449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd0b051580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce848ebe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccea5d1c40>]}
[0m16:00:25.281148 [debug] [MainThread]: Flushing usage events
[0m17:27:16.863784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11207cd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f111ee660d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f111ee66250>]}


============================== 17:27:16.869825 | 473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7 ==============================
[0m17:27:16.869825 [info ] [MainThread]: Running with dbt=1.7.11
[0m17:27:16.870817 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/home/data_jobs/airflow-dev/dags/dbt/data_pipeline/logs', 'profiles_dir': '/home/data_jobs/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:27:18.321337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f111eebc850>]}
[0m17:27:18.452135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffebaa60>]}
[0m17:27:18.453462 [info ] [MainThread]: Registered adapter: bigquery=1.7.7
[0m17:27:18.465606 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m17:27:18.507816 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:27:18.508618 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:27:18.509758 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.data_pipeline.core
- models.data_pipeline.staging
[0m17:27:18.518147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffb4e0d0>]}
[0m17:27:18.539149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffc50a60>]}
[0m17:27:18.540056 [info ] [MainThread]: Found 2 models, 4 tests, 0 sources, 0 exposures, 0 metrics, 454 macros, 0 groups, 0 semantic models
[0m17:27:18.540740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffdcdd90>]}
[0m17:27:18.543035 [info ] [MainThread]: 
[0m17:27:18.544373 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m17:27:18.546566 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_de-data-jobs'
[0m17:27:18.547559 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:27:18.745664 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_de-data-jobs, now create_de-data-jobs_dbt_dw)
[0m17:27:18.747161 [debug] [ThreadPool]: Creating schema "database: "de-data-jobs"
schema: "dbt_dw"
"
[0m17:27:18.761990 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:27:18.767878 [debug] [ThreadPool]: On create_de-data-jobs_dbt_dw: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "connection_name": "create_de-data-jobs_dbt_dw"} */
create schema if not exists `de-data-jobs`.`dbt_dw`
  
[0m17:27:19.183933 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:7517ddc2-fa72-441d-831f-99776d78c658&page=queryresults
[0m17:27:19.906273 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_de-data-jobs_dbt_dw, now list_de-data-jobs_dbt_dw)
[0m17:27:19.907494 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:27:20.095007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffefae20>]}
[0m17:27:20.096635 [info ] [MainThread]: Concurrency: 10 threads (target='dev')
[0m17:27:20.097349 [info ] [MainThread]: 
[0m17:27:20.104104 [debug] [Thread-1  ]: Began running node model.data_pipeline.my_first_dbt_model
[0m17:27:20.105409 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_dw.my_first_dbt_model ......................... [RUN]
[0m17:27:20.108745 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_de-data-jobs_dbt_dw, now model.data_pipeline.my_first_dbt_model)
[0m17:27:20.110273 [debug] [Thread-1  ]: Began compiling node model.data_pipeline.my_first_dbt_model
[0m17:27:20.127079 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_pipeline.my_first_dbt_model"
[0m17:27:20.129050 [debug] [Thread-1  ]: Timing info for model.data_pipeline.my_first_dbt_model (compile): 17:27:20.111292 => 17:27:20.128568
[0m17:27:20.129973 [debug] [Thread-1  ]: Began executing node model.data_pipeline.my_first_dbt_model
[0m17:27:20.189124 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_pipeline.my_first_dbt_model"
[0m17:27:20.191033 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:27:20.197527 [debug] [Thread-1  ]: On model.data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "model.data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `de-data-jobs`.`dbt_dw`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m17:27:20.606742 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:e9a4152e-be80-4dd0-8c97-47d599811a12&page=queryresults
[0m17:27:22.584488 [debug] [Thread-1  ]: Timing info for model.data_pipeline.my_first_dbt_model (execute): 17:27:20.130565 => 17:27:22.584098
[0m17:27:22.585867 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffe79700>]}
[0m17:27:22.586936 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_dw.my_first_dbt_model .................... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.48s]
[0m17:27:22.587949 [debug] [Thread-1  ]: Finished running node model.data_pipeline.my_first_dbt_model
[0m17:27:22.589578 [debug] [Thread-3  ]: Began running node model.data_pipeline.my_second_dbt_model
[0m17:27:22.590524 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_dw.my_second_dbt_model ......................... [RUN]
[0m17:27:22.592021 [debug] [Thread-3  ]: Acquiring new bigquery connection 'model.data_pipeline.my_second_dbt_model'
[0m17:27:22.592762 [debug] [Thread-3  ]: Began compiling node model.data_pipeline.my_second_dbt_model
[0m17:27:22.597807 [debug] [Thread-3  ]: Writing injected SQL for node "model.data_pipeline.my_second_dbt_model"
[0m17:27:22.599394 [debug] [Thread-3  ]: Timing info for model.data_pipeline.my_second_dbt_model (compile): 17:27:22.593247 => 17:27:22.598988
[0m17:27:22.600210 [debug] [Thread-3  ]: Began executing node model.data_pipeline.my_second_dbt_model
[0m17:27:22.630294 [debug] [Thread-3  ]: Writing runtime sql for node "model.data_pipeline.my_second_dbt_model"
[0m17:27:22.631777 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:27:22.637812 [debug] [Thread-3  ]: On model.data_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "model.data_pipeline.my_second_dbt_model"} */


  create or replace view `de-data-jobs`.`dbt_dw`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `de-data-jobs`.`dbt_dw`.`my_first_dbt_model`
where id = 1;


[0m17:27:22.931180 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=de-data-jobs&j=bq:US:3b4c8766-bbd8-4118-b4d5-6909086f9675&page=queryresults
[0m17:27:23.168990 [debug] [Thread-3  ]: Timing info for model.data_pipeline.my_second_dbt_model (execute): 17:27:22.600763 => 17:27:23.168621
[0m17:27:23.170431 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '473a4b17-1bcb-4eb7-ae81-a61e8cc7d0e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffaece50>]}
[0m17:27:23.171485 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_dw.my_second_dbt_model .................... [[32mCREATE VIEW (0 processed)[0m in 0.58s]
[0m17:27:23.172472 [debug] [Thread-3  ]: Finished running node model.data_pipeline.my_second_dbt_model
[0m17:27:23.175840 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:27:23.176550 [debug] [MainThread]: Connection 'model.data_pipeline.my_first_dbt_model' was properly closed.
[0m17:27:23.177172 [debug] [MainThread]: Connection 'model.data_pipeline.my_second_dbt_model' was properly closed.
[0m17:27:23.177868 [info ] [MainThread]: 
[0m17:27:23.178622 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.63 seconds (4.63s).
[0m17:27:23.179927 [debug] [MainThread]: Command end result
[0m17:27:23.196244 [info ] [MainThread]: 
[0m17:27:23.197107 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:27:23.197748 [info ] [MainThread]: 
[0m17:27:23.198375 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:27:23.199328 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.4051094, "process_user_time": 4.715906, "process_kernel_time": 0.272037, "process_mem_max_rss": "234780", "process_out_blocks": "1896", "process_in_blocks": "0"}
[0m17:27:23.200614 [debug] [MainThread]: Command `dbt run` succeeded at 17:27:23.200011 after 6.41 seconds
[0m17:27:23.201393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11207cd250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffd86100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ffebaa60>]}
[0m17:27:23.202099 [debug] [MainThread]: Flushing usage events
